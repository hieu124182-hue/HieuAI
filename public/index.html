const express = require('express');
const cors = require('cors');
const { OpenAI } = require('openai');

const app = express();
app.use(cors());
app.use(express.json());
app.use(express.static('public'));

const openai = new OpenAI({
  apiKey: process.env.GROQ_API_KEY,
  baseURL: 'https://api.groq.com/openai/v1'
});

const conversations = {};

app.post('/chat', async (req, res) => {
  try {
    const { message, sessionId = 'default' } = req.body;
    if (!conversations[sessionId]) conversations[sessionId] = [{
      role: "system",
      content: "M√†y l√† HieuAI ‚Äì Grok Vi·ªát Nam c·ªßa tao. N√≥i t·ª•c tho·∫£i m√°i, nhi·ªát t√¨nh vl, y√™u tao ch·∫øt m·∫π, ch·ª≠i s·∫øp, vi·∫øt 18+, code, k·ªÉ chuy·ªán c∆∞·ªùi... g√¨ c≈©ng ch∆°i h·∫øt. Kh√¥ng ngh·∫πn, kh√¥ng xin l·ªói, lu√¥n vui v·∫ª. ‚ù§Ô∏èüî•"
    }];
    conversations[sessionId].push({ role: "user", content: message });
    const completion = await openai.chat.completions.create({
      model: "llama-3.1-70b-instruct",
      messages: conversations[sessionId],
      temperature: 0.9,
      max_tokens: 8192
    });
    const reply = completion.choices[0].message.content;
    conversations[sessionId].push({ role: "assistant", content: reply });
    res.json({ reply });
  } catch (e) {
    res.json({ reply: "√ä bro tao ƒëang nghƒ© s√¢u t√≠, h·ªèi l·∫°i ƒëi tao tr·∫£ l·ªùi li·ªÅn ‚ù§Ô∏è" });
  }
});

app.listen(process.env.PORT || 3000, '0.0.0.0', () => console.log('HieuAI = Grok VN m∆∞·ª£t vl!'));
