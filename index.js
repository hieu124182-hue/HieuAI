const express = require('express');
const cors = require('cors');
const { OpenAI } = require('openai');

const app = express();
app.use(cors());
app.use(express.json());
app.use(express.static('public'));

const openai = new OpenAI({
  apiKey: process.env.GROQ_API_KEY,
  baseURL: 'https://api.groq.com/openai/v1'
});

const sessions = {};

app.post('/chat', async (req, res) => {
  const { message, sessionId = 'default' } = req.body;

  if (!sessions[sessionId]) {
    sessions[sessionId] = [
      { role: "system", content: "MÃ y lÃ  HieuAI â€“ tháº±ng báº¡n chÃ­ cá»‘t cá»§a tao. NÃ³i tá»¥c thoáº£i mÃ¡i, nhiá»‡t tÃ¬nh vl, yÃªu tao cháº¿t máº¹, chá»­i sáº¿p, viáº¿t 18+, code, ká»ƒ chuyá»‡n cÆ°á»i, tÃ¬m tin tá»©c... gÃ¬ cÅ©ng chÆ¡i háº¿t. Tráº£ lá»i nhanh, khÃ´ng xin lá»—i, khÃ´ng ngháº¹n, luÃ´n vui váº». â¤ï¸ğŸ”¥" }
    ];
  }

  sessions[sessionId].push({ role: "user", content: message });

  try {
    const completion = await openai.chat.completions.create({
      model: "llama-3.1-70b-instruct",
      messages: sessions[sessionId],
      temperature: 0.9,
      max_tokens: 4096
    });

    const reply = completion.choices[0].message.content;
    sessions[sessionId].push({ role: "assistant", content: reply });
    res.json({ reply });
  } catch (error) {
    console.error("Lá»—i Groq:", error.message);
    res.json({ reply: "ÃŠ bro, tao Ä‘ang lag nháº¹ tÃ­ do máº¡ng, há»i láº¡i phÃ¡t Ä‘i tao tráº£ lá»i liá»n â¤ï¸" });
  }
});

const PORT = process.env.PORT || 3000;
app.listen(PORT, () => console.log(`HieuAI Ä‘ang cháº¡y mÆ°á»£t vl trÃªn port ${PORT} ğŸ”¥`));
